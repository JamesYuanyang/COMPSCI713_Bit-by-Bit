import streamlit as st
import sqlite3
import requests
import fitz  # PyMuPDFï¼Œç”¨äºå¤„ç†PDFæ–‡ä»¶
from docx import Document  # ç”¨äºå¤„ç†Wordæ–‡æ¡£

# ---------- æ•°æ®åº“ç®¡ç† ----------
def init_db():
    # åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºå­˜å‚¨APIé…ç½®çš„è¡¨
    conn = sqlite3.connect("api_data.db")
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS credentials (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            api_key TEXT,
            deployment_url TEXT
        )
    ''')
    conn.commit()
    conn.close()

def get_credentials():
    # è·å–æœ€æ–°ä¸€æ¡APIé…ç½®
    conn = sqlite3.connect("api_data.db")
    c = conn.cursor()
    c.execute("SELECT api_key, deployment_url FROM credentials ORDER BY id DESC LIMIT 1")
    row = c.fetchone()
    conn.close()
    return row

def save_credentials(api_key, deployment_url):
    # ä¿å­˜ç”¨æˆ·è¾“å…¥çš„API Keyå’Œéƒ¨ç½²URL
    conn = sqlite3.connect("api_data.db")
    c = conn.cursor()
    c.execute("INSERT INTO credentials (api_key, deployment_url) VALUES (?, ?)", (api_key, deployment_url))
    conn.commit()
    conn.close()

# ---------- IBM Token è·å– ----------
def get_ibm_token(api_key):
    # ä½¿ç”¨API Keyä»IBM Cloudè·å–è®¿é—®ä»¤ç‰Œ
    token_url = 'https://iam.cloud.ibm.com/identity/token'
    data = {
        "apikey": api_key,
        "grant_type": 'urn:ibm:params:oauth:grant-type:apikey'
    }
    response = requests.post(token_url, data=data)
    if response.status_code == 200:
        return response.json()["access_token"]
    else:
        st.error("âŒ Failed to retrieve token. Please check your API Key.")
        return None

# ---------- æ¨¡å‹æ¨ç† ----------
def perform_inference(messages, token, deployment_url):
    # å‘é€å¸¦ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯ç»™æ¨¡å‹æœåŠ¡è¿›è¡Œæ¨ç†
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}'
    }
    payload = {
        "messages": messages
    }
    response = requests.post(deployment_url, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()
    else:
        st.error(f"âŒ Model call failed: {response.status_code} - {response.text}")
        return None

# ---------- æ–‡ä»¶æ–‡æœ¬æå– ----------
def extract_text_from_pdf(pdf_file):
    # ä»PDFæ–‡ä»¶ä¸­æå–æ–‡å­—
    text = ""
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    for page in doc:
        text += page.get_text()
    return text

def extract_text_from_docx(docx_file):
    # ä»Wordæ–‡æ¡£ä¸­æå–æ–‡å­—
    doc = Document(docx_file)
    return "\n".join(p.text for p in doc.paragraphs)

# ---------- UI åˆå§‹åŒ– ----------
st.set_page_config(page_title="Watsonx Human Ethics Assistant", layout="centered")
st.title("ğŸ“‹ Human Ethics Checker - IBM Watsonx")

init_db()  # åˆå§‹åŒ–æ•°æ®åº“
credentials = get_credentials()
default_api_key = credentials[0] if credentials else ""
default_deployment_url = credentials[1] if credentials else ""

# åˆå§‹åŒ–èŠå¤©å†å²session
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ---------- API é…ç½®åŒºå— ----------
with st.expander("ğŸ” Configure API Key and Deployment URL"):
    api_key = st.text_input("API Key", value=default_api_key, type="password")
    deployment_url = st.text_input("Model Deployment URL", value=default_deployment_url)
    if st.button("ğŸ’¾ Save Configuration"):
        save_credentials(api_key, deployment_url)
        st.success("âœ… Configuration Saved!")

# ---------- èŠå¤©è¾“å…¥ ----------
st.subheader("ğŸ’¬ Ask About Human Ethics")
user_query = st.chat_input("Ask something like: 'Does this application meet NEAC guidelines?'")

if user_query:
    # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
    st.session_state.chat_history.append({"role": "user", "content": user_query})

    # è·å–ä»¤ç‰Œå¹¶æ‰§è¡Œæ¨ç†
    token = get_ibm_token(api_key)
    if token:
        response = perform_inference(st.session_state.chat_history, token, deployment_url)
        if response:
            reply = response["choices"][0]["message"]["content"]
            st.session_state.chat_history.append({"role": "assistant", "content": reply})

# ---------- æ˜¾ç¤ºèŠå¤©è®°å½• ----------
for msg in st.session_state.chat_history:
    speaker = "ğŸ§‘ You" if msg["role"] == "user" else "ğŸ¤– Assistant"
    st.markdown(f"**{speaker}:** {msg['content']}")

# ---------- ä¸Šä¼ æ–‡æ¡£ ----------
st.subheader("ğŸ“ Upload Research Application for Review")
uploaded_file = st.file_uploader("Upload PDF or Word Document", type=["pdf", "docx"])

if uploaded_file:
    # æ ¹æ®æ–‡ä»¶ç±»å‹æå–å†…å®¹
    if uploaded_file.name.endswith(".pdf"):
        file_text = extract_text_from_pdf(uploaded_file)
    elif uploaded_file.name.endswith(".docx"):
        file_text = extract_text_from_docx(uploaded_file)
    else:
        st.error("Only PDF and DOCX are supported.")
        file_text = None

    if file_text:
        # æˆåŠŸåŠ è½½æ–‡ä»¶åæ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
        st.success("âœ… File loaded successfully!")
        st.text_area("ğŸ“„ File Preview", file_text[:1500] + "...", height=300)

        if st.button("ğŸ” Analyze This Document"):
            # å¯¹æ–‡æ¡£å‰3000å­—è¿›è¡Œåˆ†æ
            token = get_ibm_token(api_key)
            if token:
                prompt = f"As an ethics reviewer, please assess whether the following research application complies with NEAC and UAHPEC guidelines:\n\n{file_text[:3000]}"
                st.session_state.chat_history.append({"role": "user", "content": prompt})

                response = perform_inference(st.session_state.chat_history, token, deployment_url)
                if response:
                    reply = response["choices"][0]["message"]["content"]
                    st.session_state.chat_history.append({"role": "assistant", "content": reply})
